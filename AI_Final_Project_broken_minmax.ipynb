{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9ac3d5a",
      "metadata": {
        "id": "d9ac3d5a"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "id": "bb821edd",
      "metadata": {
        "id": "bb821edd"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d616f1d0",
      "metadata": {
        "id": "d616f1d0"
      },
      "source": [
        "* Make a move for X -- pick best move, train the model based on picked state and associated reward, update state\n",
        "* determine best move -- based on Q grid\n",
        "* Train Model -- x value is the state as an array, y value (target) is the q-value of best next move + reward at current state \n",
        "* Calc_value_of_state -- use model to predict value of state\n",
        "* calc target -- is the q-value of best next move + reward at current state \n",
        "* run experiment -- runs through a tictactoe game "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16201813",
      "metadata": {
        "id": "16201813"
      },
      "source": [
        "# Piece Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "id": "d87979f2",
      "metadata": {
        "id": "d87979f2"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "class Piece(Enum):\n",
        "    EMPTY = 'EMPTY'\n",
        "    BLACK = 'BLACK'\n",
        "    WHITE = 'WHITE'\n",
        "    RED = ' RED '"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d23c6c04",
      "metadata": {
        "id": "d23c6c04"
      },
      "source": [
        "# Board Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "id": "c95e6981",
      "metadata": {
        "id": "c95e6981"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class Board:\n",
        "    def __init__(self):\n",
        "        self.pieces = [[[Piece.EMPTY for k in range(3)] for j in range(3)] for i in range(3)]\n",
        "        for x in range(9):\n",
        "          a = random.randint(0,2)\n",
        "          b = random.randint(0,2)\n",
        "          c = random.randint(0,2)\n",
        "          while self.pieces[a][b][c] != Piece.EMPTY:\n",
        "            a = random.randint(0,2)\n",
        "            b = random.randint(0,2)\n",
        "            c = random.randint(0,2)\n",
        "          self.pieces[a][b][c] = Piece.BLACK\n",
        "        self.winningRuns = self.getWinningRuns()\n",
        "\n",
        "    def validMove(self,x,y,z,dir):\n",
        "        if not x in range(3) or not y in range(3) or not z in range(3):\n",
        "              return False\n",
        "        if dir == 'UP':\n",
        "              return (z == 2) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x][y][z-1] == Piece.EMPTY or self.pieces[x][y][z-2] == Piece.EMPTY)\n",
        "        if dir == 'DOWN':\n",
        "              return (z == 0) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x][y][z+1] == Piece.EMPTY or self.pieces[x][y][z+2] == Piece.EMPTY)\n",
        "        if dir == 'LEFT':\n",
        "              return (x == 2) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x-1][y][z] == Piece.EMPTY or self.pieces[x-2][y][z] == Piece.EMPTY)\n",
        "        if dir == 'RIGHT':\n",
        "              return (x == 0) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x+1][y][z] == Piece.EMPTY or self.pieces[x+2][y][z] == Piece.EMPTY)\n",
        "        if dir == 'FRONT':\n",
        "              return (y == 2) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x][y-1][z] == Piece.EMPTY or self.pieces[x][y-2][z] == Piece.EMPTY)\n",
        "        if dir == 'BACK':\n",
        "              return (y == 0) and (self.pieces[x][y][z] == Piece.EMPTY or self.pieces[x][y+1][z] == Piece.EMPTY or self.pieces[x][y+2][z] == Piece.EMPTY)\n",
        "        else:\n",
        "              return False\n",
        "            \n",
        "    def move(self,x,y,z,dir,player: Piece):\n",
        "        if not self.validMove(x,y,z,dir):\n",
        "             raise ValueError\n",
        "        else:\n",
        "            if (self.pieces[x][y][z] == Piece.EMPTY):\n",
        "                self.pieces[x][y][z] = player\n",
        "            else:\n",
        "                if dir == 'UP':\n",
        "                    if (self.pieces[x][y][z-1] == Piece.EMPTY):\n",
        "                        self.pieces[x][y][z-1] = self.pieces[x][y][z]\n",
        "                        self.pieces[x][y][z] = player\n",
        "                    else:\n",
        "                        self.pieces[x][y][z-2] = self.pieces[x][y][z-1]\n",
        "                        self.pieces[x][y][z-1] = self.pieces[x][y][z]\n",
        "                        self.pieces[x][y][z] = player\n",
        "                elif dir == 'DOWN':\n",
        "                      if (self.pieces[x][y][z+1] == Piece.EMPTY):\n",
        "                          self.pieces[x][y][z+1] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                      else:\n",
        "                          self.pieces[x][y][z+2] = self.pieces[x][y][z+1]\n",
        "                          self.pieces[x][y][z+1] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                elif dir == 'LEFT':\n",
        "                      if (self.pieces[x-1][y][z] == Piece.EMPTY):\n",
        "                          self.pieces[x-1][y][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                      else:\n",
        "                          self.pieces[x-2][y][z] = self.pieces[x-1][y][z]\n",
        "                          self.pieces[x-1][y][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                elif dir == 'RIGHT':\n",
        "                      if (self.pieces[x+1][y][z] == Piece.EMPTY):\n",
        "                          self.pieces[x+1][y][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                      else:\n",
        "                          self.pieces[x+2][y][z] = self.pieces[x+1][y][z]\n",
        "                          self.pieces[x+1][y][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                elif dir == 'FRONT':\n",
        "                      if (self.pieces[x][y-1][z] == Piece.EMPTY):\n",
        "                          self.pieces[x][y-1][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                      else:\n",
        "                          self.pieces[x][y-2][z] = self.pieces[x][y-1][z]\n",
        "                          self.pieces[x][y-1][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                elif dir == 'BACK':\n",
        "                      if (self.pieces[x][y+1][z] == Piece.EMPTY):\n",
        "                          self.pieces[x][y+1][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "                      else:\n",
        "                          self.pieces[x][y+2][z] = self.pieces[x][y+1][z]\n",
        "                          self.pieces[x][y+1][z] = self.pieces[x][y][z]\n",
        "                          self.pieces[x][y][z] = player\n",
        "\n",
        "    def getGameState(self):\n",
        "        gameState = \"+----------------------\\n\"\n",
        "        gameState += \"| \\ \" + self.pieces[0][2][0].value + \"  \" + self.pieces[1][2][0].value + \"  \" + self.pieces[2][2][0].value + \" \\\\\\n\"\n",
        "        gameState += \"|   \\                     \\\\\\n\"\n",
        "        gameState += \"|     \\ \" + self.pieces[0][1][0].value + \"  \" + self.pieces[1][1][0].value + \"  \" + self.pieces[2][1][0].value + \" \\\\\\n\"\n",
        "        gameState += \"|       \\                     \\\\\\n\"\n",
        "        gameState += \"|         \\ \" + self.pieces[0][0][0].value + \"  \" + self.pieces[1][0][0].value + \"  \" + self.pieces[2][0][0].value + \" \\\\\\n\"\n",
        "        gameState += \"|          ---------------------|\\n\"\n",
        "        gameState += \"|   \" + self.pieces[0][2][1].value + \" |\" + self.pieces[1][2][1].value + \"  \" + self.pieces[2][2][1].value + \"         |\\n\"\n",
        "        gameState += \"|         |                     |\\n\"\n",
        "        gameState += \"|       \" + self.pieces[0][1][1].value + \"  \" + self.pieces[1][1][1].value + \"  \" + self.pieces[2][1][1].value + \"     |\\n\"\n",
        "        gameState += \"|         |                     |\\n\"\n",
        "        gameState += \"|         | \" + self.pieces[0][0][1].value + \"  \" + self.pieces[1][0][1].value + \"  \" + self.pieces[2][0][1].value + \" |\\n\"\n",
        "        gameState += \"|         |                     |\\n\"\n",
        "        gameState += \" \\ \" + self.pieces[0][2][2].value + \"  \" + self.pieces[1][2][2].value + \"  \" + self.pieces[2][2][2].value + \"          |\\n\"\n",
        "        gameState += \"   \\      |                     |\\n\"\n",
        "        gameState += \"     \\ \" + self.pieces[0][1][2].value + \"  \" + self.pieces[1][1][2].value + \"  \" + self.pieces[2][1][2].value + \"      |\\n\"\n",
        "        gameState += \"       \\  |                     |\\n\"\n",
        "        gameState += \"         \\| \" + self.pieces[0][0][2].value + \"  \" + self.pieces[1][0][2].value + \"  \" + self.pieces[2][0][2].value + \" |\\n\"\n",
        "        gameState += \"           ---------------------+\\n\\n\"\n",
        "        return gameState\n",
        "    \n",
        "\n",
        "    def getWinningRuns(self):\n",
        "        runs = []\n",
        "\n",
        "        runs.append([(0,0,0),(0,0,1),(0,0,2)])\n",
        "        runs.append([(0,0,0),(0,1,0),(0,2,0)])\n",
        "        runs.append([(0,0,0),(1,0,0),(2,0,0)])\n",
        "\n",
        "        runs.append([(2,2,0),(1,2,0),(0,2,0)])\n",
        "        runs.append([(2,2,0),(2,1,0),(2,0,0)])\n",
        "        runs.append([(2,2,0),(2,2,1),(2,2,2)])\n",
        "\n",
        "        runs.append([(0,2,2),(0,1,2),(0,0,2)])\n",
        "        runs.append([(0,2,2),(1,2,2),(2,2,2)])\n",
        "        runs.append([(0,2,2),(0,2,1),(0,2,0)])\n",
        "\n",
        "        runs.append([(2,0,2),(2,0,1),(2,0,0)])\n",
        "        runs.append([(2,0,2),(1,0,2),(0,0,2)])\n",
        "        runs.append([(2,0,2),(2,1,2),(2,2,2)])\n",
        "        # Front\n",
        "        runs.append([(0,0,0),(1,0,1),(2,0,2)])\n",
        "        runs.append([(0,0,2),(1,0,1),(2,0,0)])\n",
        "        runs.append([(1,0,0),(1,0,1),(1,0,2)])\n",
        "        runs.append([(0,0,1),(1,0,1),(2,0,1)])\n",
        "        # Top\n",
        "        runs.append([(0,0,0),(1,1,0),(2,2,0)])\n",
        "        runs.append([(0,2,0),(1,1,0),(2,0,0)])\n",
        "        runs.append([(0,1,0),(1,1,0),(2,1,0)])\n",
        "        runs.append([(1,2,0),(1,1,0),(1,0,0)])\n",
        "        # Left\n",
        "        runs.append([(0,0,0),(0,1,1),(0,2,2)])\n",
        "        runs.append([(0,0,2),(0,1,1),(0,2,0)])\n",
        "        runs.append([(0,0,1),(0,1,1),(0,2,1)])\n",
        "        runs.append([(0,1,0),(0,1,1),(0,1,2)])\n",
        "        # Back\n",
        "        runs.append([(0,2,2),(1,2,1),(2,2,0)])\n",
        "        runs.append([(0,2,0),(1,2,1),(2,2,2)])\n",
        "        runs.append([(1,2,0),(1,2,1),(1,2,2)])\n",
        "        runs.append([(0,2,1),(1,2,1),(2,2,1)])\n",
        "        # Right\n",
        "        runs.append([(2,0,2),(2,1,1),(2,2,0)])\n",
        "        runs.append([(2,0,0),(2,1,1),(2,2,2)])\n",
        "        runs.append([(2,0,1),(2,1,1),(2,2,1)])\n",
        "        runs.append([(2,1,0),(2,1,1),(2,1,2)])\n",
        "        # Bottom\n",
        "        runs.append([(2,0,2),(1,1,2),(0,2,2)])\n",
        "        runs.append([(0,0,2),(1,1,2),(2,2,2)])\n",
        "        runs.append([(0,1,2),(1,1,2),(2,1,2)])\n",
        "        runs.append([(1,0,2),(1,1,2),(1,2,2)])\n",
        "        # Corners\n",
        "        runs.append([(0,0,0),(1,1,1),(2,2,2)])\n",
        "        runs.append([(2,0,0),(1,1,1),(0,2,2)])\n",
        "        runs.append([(2,2,0),(1,1,1),(0,0,2)])\n",
        "        runs.append([(0,2,0),(1,1,1),(2,0,2)])\n",
        "        # Edges\n",
        "        runs.append([(1,0,0),(1,1,1),(1,2,2)])\n",
        "        runs.append([(2,1,0),(1,1,1),(0,1,2)])\n",
        "        runs.append([(1,2,0),(1,1,1),(1,0,2)])\n",
        "        runs.append([(0,1,0),(1,1,1),(2,1,2)])\n",
        "        runs.append([(0,0,1),(1,1,1),(2,2,1)])\n",
        "        runs.append([(2,0,1),(1,1,1),(0,2,1)])\n",
        "        # Middles\n",
        "        runs.append([(1,1,0),(1,1,1),(1,1,2)])\n",
        "        runs.append([(1,0,1),(1,1,1),(1,2,1)])\n",
        "        runs.append([(0,1,1),(1,1,1),(2,1,1)])\n",
        "\n",
        "        return runs\n",
        "\n",
        "    def getPossibleMoves(self):\n",
        "        directions = ['UP','DOWN','LEFT','RIGHT','FRONT','BACK']\n",
        "        moves = []\n",
        "        for x in range(2):\n",
        "          for y in range(2):\n",
        "            for z in range(2):\n",
        "              for dir in directions:\n",
        "                if self.validMove(x,y,z,dir):\n",
        "                  moves.append((x,y,z,dir))\n",
        "        return moves\n",
        "\n",
        "    def getWinInOne(self,player: Piece):\n",
        "        for (x,y,z,dir) in self.getPossibleMoves():\n",
        "          c = copy.deepcopy(self)\n",
        "          c.move(x,y,z,dir,player)\n",
        "          if c.hasWon(player):\n",
        "            return (x,y,z,dir)\n",
        "        return None\n",
        "\n",
        "    def otherPlayer(self,player: Piece):\n",
        "        return Piece.RED if player == Piece.WHITE else Piece.WHITE\n",
        "\n",
        "    def getDefendingMove(self,player: Piece):\n",
        "        potential_moves = []\n",
        "        for (x,y,z,dir) in self.getPossibleMoves():\n",
        "          c = copy.deepcopy(self)\n",
        "          c.move(x,y,z,dir,player)\n",
        "          if c.getWinInOne(self.otherPlayer(player)) == None:\n",
        "            potential_moves.append((x,y,z,dir))\n",
        "        if potential_moves:\n",
        "          return random.choice(potential_moves)\n",
        "        return None\n",
        "\n",
        "    def getWinInTwo(self,player: Piece):\n",
        "        potential_moves = []\n",
        "        for (x,y,z,dir) in self.getPossibleMoves():\n",
        "          c = copy.deepcopy(self)\n",
        "          c.move(x,y,z,dir,player)\n",
        "          if c.getWinInOne(self.otherPlayer(player)) == None:\n",
        "            winner = True\n",
        "            for (x2,y2,z2,dir2) in c.getPossibleMoves():\n",
        "              c2 = copy.deepcopy(c)\n",
        "              c2.move(x2,y2,z2,dir2,self.otherPlayer(player))\n",
        "              if c2.getWinInOne(player) == None:\n",
        "                winner = False\n",
        "            if winner:\n",
        "              potential_moves.append((x,y,z,dir))\n",
        "        if potential_moves:\n",
        "          return random.choice(potential_moves)\n",
        "        return None\n",
        "\n",
        "    def getRandomMove(self,player: Piece):\n",
        "        directions = ['UP','DOWN','LEFT','RIGHT','FRONT','BACK']\n",
        "        x = random.randint(0,2)\n",
        "        y = random.randint(0,2)\n",
        "        z = random.randint(0,2)\n",
        "        dir = random.choice(directions)\n",
        "        while not self.validMove(x,y,z,dir):\n",
        "            x = random.randint(0,2)\n",
        "            y = random.randint(0,2)\n",
        "            z = random.randint(0,2)\n",
        "            dir = random.choice(directions)\n",
        "        return (x,y,z,dir)\n",
        "\n",
        "    def hasWon(self,player: Piece):\n",
        "        for run in self.winningRuns:\n",
        "            if all(self.pieces[x][y][z] == player for (x,y,z) in run):\n",
        "                return True\n",
        "        return False\n",
        "    \n",
        "    def gameOver(self):\n",
        "        return self.hasWon(Piece.RED) or self.hasWon(Piece.WHITE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c90742e7",
      "metadata": {
        "id": "c90742e7"
      },
      "source": [
        "# Random Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "id": "919b0d5d",
      "metadata": {
        "id": "919b0d5d"
      },
      "outputs": [],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self,player):\n",
        "        self.player = player\n",
        "\n",
        "    def getMove(self, board: Board):\n",
        "        return board.getRandomMove(self.player)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Easy Agent"
      ],
      "metadata": {
        "id": "FNIKVDWcIZXz"
      },
      "id": "FNIKVDWcIZXz"
    },
    {
      "cell_type": "code",
      "source": [
        "class EasyAgent:\n",
        "    def __init__(self,player):\n",
        "        self.player = player\n",
        "\n",
        "    def getMove(self, board: Board):\n",
        "        winningMove = board.getWinInOne(self.player)\n",
        "        if winningMove:\n",
        "          return winningMove\n",
        "        else:\n",
        "          return board.getRandomMove(self.player)"
      ],
      "metadata": {
        "id": "oiGGigmkIdv_"
      },
      "id": "oiGGigmkIdv_",
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medium Agent"
      ],
      "metadata": {
        "id": "9JkgzsI3uMcs"
      },
      "id": "9JkgzsI3uMcs"
    },
    {
      "cell_type": "code",
      "source": [
        "class MediumAgent:\n",
        "    def __init__(self,player):\n",
        "        self.player = player\n",
        "\n",
        "    def getMove(self, board: Board):\n",
        "        winningMove = board.getWinInOne(self.player)\n",
        "        if winningMove:\n",
        "          return winningMove\n",
        "        else:\n",
        "          defendingMove = board.getDefendingMove(self.player)\n",
        "          if defendingMove:\n",
        "            return defendingMove\n",
        "          else:\n",
        "            return board.getRandomMove(self.player)"
      ],
      "metadata": {
        "id": "0StiPGknuITm"
      },
      "id": "0StiPGknuITm",
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hard Agent"
      ],
      "metadata": {
        "id": "9ho8XxlS13pv"
      },
      "id": "9ho8XxlS13pv"
    },
    {
      "cell_type": "code",
      "source": [
        "class HardAgent:\n",
        "    def __init__(self,player):\n",
        "        self.player = player\n",
        "\n",
        "    def getMove(self, board: Board):\n",
        "        winningMove = board.getWinInOne(self.player)\n",
        "        if winningMove:\n",
        "          return winningMove\n",
        "        else:\n",
        "          winInTwo = board.getWinInTwo(self.player)\n",
        "          if winInTwo:\n",
        "            return winInTwo\n",
        "          else:\n",
        "            defendingMove = board.getDefendingMove(self.player)\n",
        "            if defendingMove:\n",
        "              return defendingMove\n",
        "            else:\n",
        "              return board.getRandomMove(self.player)"
      ],
      "metadata": {
        "id": "krHzapzO16Oc"
      },
      "id": "krHzapzO16Oc",
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minmax Agent"
      ],
      "metadata": {
        "id": "HDxGqeuwbCxJ"
      },
      "id": "HDxGqeuwbCxJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "class MinMaxAgent():\n",
        "  global P1WIN\n",
        "  P1WIN = 1000000\n",
        "  global P2WIN\n",
        "  P2WIN = -1000000\n",
        "    \n",
        "\n",
        "  def __init__(self,player):\n",
        "        self.player1 = player\n",
        "        self.player2 = Board().otherPlayer(player)\n",
        "\n",
        "  # P1 corner piece -> 1 pt\n",
        "  # P2 corner piece -> -1 pt\n",
        "  # P1 runs of 2 -> 10 pts\n",
        "  # P2 runs of 2 -> -10 pts\n",
        "  # P1 win in 1's / win in 2's -> 1000000 pts\n",
        "  # P2 win in 1's / win in 2's -> -1000000 pts\n",
        "  def evalPos(self,board: Board, p1, p2):\n",
        "    value = 0\n",
        "    for x in [0,2]:\n",
        "      for y in [0,2]:\n",
        "        for z in [0,2]:\n",
        "          if board.pieces[x][y][z] == p1:\n",
        "            value += 1\n",
        "          if board.pieces[x][y][z] == p2:\n",
        "            value -= 1\n",
        "    for run in board.getWinningRuns():\n",
        "      if (run[0] == run[1] == p1) or (run[1] == run[2] == self.player1) or (run[0] == run[2] == self.player1):\n",
        "        value += 10\n",
        "      if (run[0] == run[1] == self.player2) or (run[1] == run[2] == self.player2) or (run[0] == run[2] == self.player2):\n",
        "        value -= 10\n",
        "    if board.getWinInOne(self.player1) != None:\n",
        "      return P1WIN\n",
        "    if board.getWinInOne(self.player2) != None:\n",
        "      return P2WIN\n",
        "    return value\n",
        "\n",
        "  def minMax(self, board, player, depth, alpha, beta):\n",
        "      maxDepth = 4\n",
        "      \n",
        "      # evaluate the current board using eval(...) and then return its score if this is a leaf node, i.e.,\n",
        "      # you have reached the maximum depth, or it is a win for one of the players\n",
        "      cur_score = self.evalPos(board, player, board.otherPlayer(player))\n",
        "      if depth == maxDepth:\n",
        "        return (cur_score,None)\n",
        "      if cur_score in [P2WIN, P1WIN]:\n",
        "        return (cur_score,None)\n",
        "      \n",
        "      # Otherwise, as in lecture, consider whether this is a maximizing player (O) or minimizing\n",
        "      # player (X) and perform the min-max algorithm with alpha-beta pruning, plus whatever\n",
        "      # additional strategies you can come up with\n",
        "      \n",
        "      # Note that when you make a recursive call, you don't need the move, so can just do:\n",
        "      #         (score,_) = minMax(.....)\n",
        "      if player == self.player1:\n",
        "        value = P2WIN\n",
        "        move = board.getRandomMove(player)\n",
        "        for (x,y,z,dir) in board.getPossibleMoves():\n",
        "          board_copy = copy.deepcopy(board.pieces)\n",
        "          board.move(x,y,z,dir,player)\n",
        "          new_score = self.minMax(board,self.player2,depth+1,alpha,beta)[0]\n",
        "          board.pieces = board_copy\n",
        "          if new_score > value:\n",
        "            value = new_score\n",
        "            move = (x,y,z,dir)\n",
        "          alpha = max(alpha, value)\n",
        "          if alpha >= beta:\n",
        "            break\n",
        "        return (value,move)\n",
        "      else:\n",
        "        value = P1WIN\n",
        "        move = board.getRandomMove(player)\n",
        "        for (x,y,z,dir) in board.getPossibleMoves():\n",
        "          board_copy = copy.deepcopy(board.pieces)\n",
        "          board.move(x,y,z,dir,player)\n",
        "          new_score = self.minMax(board,self.player1,depth+1,alpha,beta)[0]\n",
        "          board.pieces = board_copy\n",
        "          if new_score < value:\n",
        "            value = new_score\n",
        "            move = (x,y,z,dir)\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "              break\n",
        "        return (value,move)\n",
        "      \n",
        "  # You will use this function in your interactive version below\n",
        "\n",
        "  def getMove(self, board): \n",
        "      (_,move) = self.minMax(board,self.player1,0,-sys.maxsize,sys.maxsize)    # only place we need the move\n",
        "      if move == None:\n",
        "        print(board.getGameState())\n",
        "        print(board.getWinInOne(self.player1))\n",
        "        return board.getWinInOne(self.player1) or board.getRandomMove(self.player1)\n",
        "      return move"
      ],
      "metadata": {
        "id": "nxrOzxbbElmG"
      },
      "id": "nxrOzxbbElmG",
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GamePlayer:\n",
        "    def __init__(self,player1,player2):\n",
        "      self.player1 = player1\n",
        "      self.player2 = player2\n",
        "      self.board = Board()\n",
        "\n",
        "    def playGame(self):\n",
        "       self.board = Board()\n",
        "       while 1 == 1:\n",
        "          # Player 1 moves\n",
        "          (x1,y1,z1,dir1) = self.player1.getMove(self.board)\n",
        "          self.board.move(x1,y1,z1,dir1,Piece.RED)\n",
        "          if self.board.hasWon(Piece.RED):\n",
        "             return 'RED'\n",
        "          # Player 2 moves\n",
        "          (x2,y2,z2,dir2) = self.player2.getMove(self.board)\n",
        "          self.board.move(x2,y2,z2,dir2,Piece.WHITE)\n",
        "          if self.board.hasWon(Piece.WHITE):\n",
        "             return 'WHITE'"
      ],
      "metadata": {
        "id": "yQkDHXTzCgTq"
      },
      "id": "yQkDHXTzCgTq",
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "150be10c",
      "metadata": {
        "id": "150be10c"
      },
      "source": [
        "# Main Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "id": "194f2e2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "194f2e2e",
        "outputId": "f1b2287f-1f6e-4a24-d40e-e75309766668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [00:49<03:20, 25.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ EMPTY  BLACK  BLACK \\\n",
            "|   \\                     \\\n",
            "|     \\ EMPTY  EMPTY  BLACK \\\n",
            "|       \\                     \\\n",
            "|         \\  RED   WHITE  EMPTY \\\n",
            "|          ---------------------|\n",
            "|   BLACK |EMPTY  BLACK         |\n",
            "|         |                     |\n",
            "|       BLACK  EMPTY  EMPTY     |\n",
            "|         |                     |\n",
            "|         |  RED   WHITE  EMPTY |\n",
            "|         |                     |\n",
            " \\ EMPTY  BLACK  EMPTY          |\n",
            "   \\      |                     |\n",
            "     \\ EMPTY  BLACK  EMPTY      |\n",
            "       \\  |                     |\n",
            "         \\| WHITE   RED   BLACK |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [01:34<02:22, 23.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ EMPTY  BLACK  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\  RED   BLACK  BLACK \\\n",
            "|       \\                     \\\n",
            "|         \\ WHITE   RED   WHITE \\\n",
            "|          ---------------------|\n",
            "|   BLACK |EMPTY  EMPTY         |\n",
            "|         |                     |\n",
            "|       EMPTY  EMPTY  EMPTY     |\n",
            "|         |                     |\n",
            "|         | BLACK  BLACK  EMPTY |\n",
            "|         |                     |\n",
            " \\ BLACK  BLACK  BLACK          |\n",
            "   \\      |                     |\n",
            "     \\ EMPTY  EMPTY  EMPTY      |\n",
            "       \\  |                     |\n",
            "         \\| EMPTY  EMPTY  EMPTY |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:58<02:00, 24.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ EMPTY  BLACK  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\ WHITE   RED   WHITE \\\n",
            "|       \\                     \\\n",
            "|         \\  RED   BLACK  EMPTY \\\n",
            "|          ---------------------|\n",
            "|   BLACK |EMPTY  EMPTY         |\n",
            "|         |                     |\n",
            "|        RED   EMPTY  BLACK     |\n",
            "|         |                     |\n",
            "|         | WHITE  BLACK  BLACK |\n",
            "|         |                     |\n",
            " \\ EMPTY  EMPTY  EMPTY          |\n",
            "   \\      |                     |\n",
            "     \\ BLACK  EMPTY  BLACK      |\n",
            "       \\  |                     |\n",
            "         \\| EMPTY  EMPTY  BLACK |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:27<01:42, 25.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ EMPTY  BLACK  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\ WHITE   RED   EMPTY \\\n",
            "|       \\                     \\\n",
            "|         \\  RED   WHITE  EMPTY \\\n",
            "|          ---------------------|\n",
            "|   EMPTY |BLACK  EMPTY         |\n",
            "|         |                     |\n",
            "|        RED   BLACK  EMPTY     |\n",
            "|         |                     |\n",
            "|         | WHITE   RED   BLACK |\n",
            "|         |                     |\n",
            " \\ EMPTY  EMPTY  BLACK          |\n",
            "   \\      |                     |\n",
            "     \\ BLACK  BLACK  BLACK      |\n",
            "       \\  |                     |\n",
            "         \\| WHITE  BLACK  EMPTY |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:40<01:04, 21.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ BLACK  EMPTY  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\ BLACK  BLACK  BLACK \\\n",
            "|       \\                     \\\n",
            "|         \\ WHITE   RED   EMPTY \\\n",
            "|          ---------------------|\n",
            "|   BLACK |EMPTY  EMPTY         |\n",
            "|         |                     |\n",
            "|       EMPTY  BLACK  BLACK     |\n",
            "|         |                     |\n",
            "|         |  RED   EMPTY  BLACK |\n",
            "|         |                     |\n",
            " \\ EMPTY  BLACK  EMPTY          |\n",
            "   \\      |                     |\n",
            "     \\ EMPTY  EMPTY  EMPTY      |\n",
            "       \\  |                     |\n",
            "         \\| WHITE  EMPTY  EMPTY |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [03:33<00:24, 24.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ BLACK  EMPTY  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\ WHITE  WHITE  EMPTY \\\n",
            "|       \\                     \\\n",
            "|         \\  RED    RED   WHITE \\\n",
            "|          ---------------------|\n",
            "|   EMPTY |BLACK  EMPTY         |\n",
            "|         |                     |\n",
            "|       EMPTY   RED   EMPTY     |\n",
            "|         |                     |\n",
            "|         | BLACK  BLACK  BLACK |\n",
            "|         |                     |\n",
            " \\ EMPTY  BLACK  EMPTY          |\n",
            "   \\      |                     |\n",
            "     \\ EMPTY  BLACK  EMPTY      |\n",
            "       \\  |                     |\n",
            "         \\| BLACK  EMPTY  BLACK |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:57<00:00, 23.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------\n",
            "| \\ EMPTY  EMPTY  EMPTY \\\n",
            "|   \\                     \\\n",
            "|     \\ EMPTY   RED   BLACK \\\n",
            "|       \\                     \\\n",
            "|         \\  RED   WHITE  WHITE \\\n",
            "|          ---------------------|\n",
            "|   EMPTY |BLACK  BLACK         |\n",
            "|         |                     |\n",
            "|       BLACK  BLACK  EMPTY     |\n",
            "|         |                     |\n",
            "|         | WHITE   RED   EMPTY |\n",
            "|         |                     |\n",
            " \\ EMPTY  EMPTY  BLACK          |\n",
            "   \\      |                     |\n",
            "     \\ EMPTY  BLACK  EMPTY      |\n",
            "       \\  |                     |\n",
            "         \\| BLACK  BLACK  EMPTY |\n",
            "           ---------------------+\n",
            "\n",
            "\n",
            "None\n",
            "Red player wins 20.0% of the time!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    game = GamePlayer(MinMaxAgent(Piece.RED),MediumAgent(Piece.WHITE))\n",
        "    red_wins = 0\n",
        "    games_to_play = 10\n",
        "    for i in tqdm(range(games_to_play)):\n",
        "      winner = game.playGame()\n",
        "      if winner == 'RED':\n",
        "        red_wins += 1\n",
        "    print(f'Red player wins {red_wins * 100 / games_to_play}% of the time!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b774e5a6",
      "metadata": {
        "id": "b774e5a6"
      },
      "source": [
        "# Deep Learning Agent "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2852c60a",
      "metadata": {
        "id": "2852c60a"
      },
      "source": [
        "## Method we might need \n",
        "* Make a move for X -- pick best move, train the model based on picked state and associated reward, update state\n",
        "* determine best move -- based on Q grid\n",
        "* Train Model -- x value is the state as an array, y value (target) is the q-value of best next move + reward at current state \n",
        "* Calc_value_of_state -- use model to predict value of state\n",
        "* calc target -- is the q-value of best next move + reward at current state \n",
        "* run experiment -- runs through a tictactoe game "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71782d0f",
      "metadata": {
        "id": "71782d0f"
      },
      "source": [
        "### Notes\n",
        "The value function determines how good it is to be in state s,\n",
        "Agent can also learn the value of a state-action pair, which is a q value. The q funciton \n",
        "measueres tha value of choosing a particualar action when in a particular state.\n",
        "\n",
        "\n",
        "Deep Q-Learning replaces the regular Q-table with a neural network. Rather than mapping a state-action pair to a q-value, a neural network maps input states to (action, Q-value) pairs.\n",
        "\n",
        "The Bellman equation is a recursive equation that relates the value of a state to the values of its successor states. It decomposes the value function into two parts: an immediate reward and the expected discounted value of the next state. The Bellman equation is used to update the value function iteratively, until it converges to the true value function.\n",
        "\n",
        "https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de52410a",
      "metadata": {
        "id": "de52410a"
      },
      "source": [
        "## Good code references:\n",
        "   * https://github.com/giladariel/TicTacToe_RL/blob/master/DeepTicTacToe_org.py\n",
        "   * https://github.com/mswang12/minDQN/blob/main/minDQN.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea671a2",
      "metadata": {
        "id": "4ea671a2"
      },
      "outputs": [],
      "source": [
        "def initialize_model():\n",
        "    \"\"\" Initializes keras sequential model that will read in state as an array and return list of q values associated\n",
        "    with each possible action. \n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69221f5c",
      "metadata": {
        "id": "69221f5c",
        "outputId": "28daf38b-1809-4494-a4c1-8c3525c33cae"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 9 (3076497746.py, line 10)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[51], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\" Gets the immediate reward of taking an action. Since this is tiktaktoe, if the move\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 9\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "directions = ['UP','DOWN','LEFT','RIGHT','FRONT','BACK']\n",
        "\n",
        "class DeepLearningAgent:\n",
        "    # epsilon initialized to 1 since we start random\n",
        "    def __init__(self,player=Piece.WHITE,epsilon=1, lam=1.0):\n",
        "        self.player = player\n",
        "        self.epsilon = epsilon\n",
        "        self.lam = lam\n",
        "        self.model = initialize_model()\n",
        "        \n",
        "    \"\"\" Gets the immediate reward of taking an action. Since this is tiktaktoe, if the move\n",
        "    resulted in a win, reward is 1, if a loss, reward is -1, if a tie, reward is 0.5, otherwise\n",
        "    the game has not ended and the reward is 0.\n",
        "    \"\"\"\n",
        "    def get_reward(self,board,move):\n",
        "      c = copy.deepcopy(board)\n",
        "      c.move(move)\n",
        "      # Return 1 if the move wins\n",
        "      if c.hasWon(self.player):\n",
        "        return 1\n",
        "      # Returns 0 if the move loses (opponent can win in one)\n",
        "      elif c.getWinInOne(Piece.RED if self.player == Piece.WHITE else Piece.WHITE):\n",
        "        return -1\n",
        "      # Return 0 otherwise\n",
        "      return 0\n",
        "    \n",
        "    def calculate_value():\n",
        "    \"\"\" The value of a specific state is predicted by the model which has been trained\n",
        "    on previously visisted states.\n",
        "    \"\"\"\n",
        "    \n",
        "    def calculate_target():\n",
        "    \"\"\" The target (value estimate of state s) is calculated based on the bellman equation.\n",
        "    The equation combines the immediate reward from the current state and the discounted\n",
        "    value of the best next state. y is discount factor which determines the balance of caring about short \n",
        "    vs long term rewards. Higher value, more weight towards long term rewards. The bellman equation is recursive.\n",
        "    \"\"\"\n",
        "        # target (value of state s) = (reward of state s) + y * (best q value of all possible actions from state s1)\n",
        "        # (best q value of all possible actions from state s1) is calculated by passing s1 into the model\n",
        "\n",
        "    \n",
        "    def train_model():\n",
        "    \"\"\" The model is learning the policy that the agent will use to move around the environment\n",
        "    and choose the best action. Each time the agent decides on an action, the reward (aka the \n",
        "    target) for the state (s1) is calculated. Then using s1 as x and the reward as y, the model\n",
        "    undergoes one iteration of stochastic gradient descent. The output of the model is basically \n",
        "    the models prediction for the q value of the best action. \n",
        "    \"\"\"\n",
        "        \n",
        "        # Use bellman equation (calculate_target()) to get y value\n",
        "        \n",
        "        # train model using model.fit\n",
        "        \n",
        "    def choose_best_move():\n",
        "        \n",
        "        \n",
        "    def play_move():\n",
        "        \n",
        "        # initialize empty replay_memory, as no moves have been made yet\n",
        "        \n",
        "        # if random number is less than epsilon, do random action\n",
        "        \n",
        "        # else use model to predict the best move (model.predict). This will return q value which u need to find\n",
        "        # associated move for \n",
        "        \n",
        "        \n",
        "        # add move to replay_memory. Replay_memory is a list of tuples(state,action,reward,new state)\n",
        "        \n",
        "        # call train model to update model\n",
        "        \n",
        "        # update epsilon \n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412018b1",
      "metadata": {
        "id": "412018b1"
      },
      "source": [
        "# Game Player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d3c784",
      "metadata": {
        "id": "65d3c784"
      },
      "outputs": [],
      "source": [
        "# from board import Board\n",
        "# from piece import Piece\n",
        "# from random_agent import RandomAgent\n",
        "\n",
        "class GamePlayer:\n",
        "    def __init__(self, player1= DeepLearningAgent(Piece.WHITE), player2= RandomAgent(Piece.RED)):\n",
        "        self.player1 = player1\n",
        "        self.player2 = player2\n",
        "        self.board = Board()\n",
        "\n",
        "#     def playGame(self):\n",
        "#         while 1 == 1:\n",
        "#             # Player 1 moves\n",
        "#             (x1,y1,z1,dir1) = self.player1.getMove(self.board)\n",
        "#             self.board.move(x1,y1,z1,dir1,Piece.WHITE)\n",
        "#             print(self.board.getGameState())\n",
        "#             if self.board.hasWon(Piece.WHITE):\n",
        "#                 print('White wins!')\n",
        "#                 return\n",
        "#             # Player 2 moves\n",
        "#             (x2,y2,z2,dir2) = self.player2.getMove(self.board)\n",
        "#             self.board.move(x2,y2,z2,dir2,Piece.RED)\n",
        "#             print(self.board.getGameState())\n",
        "#             if self.board.hasWon(Piece.RED):\n",
        "#                 print('Red wins!')\n",
        "#                 return\n",
        "\n",
        "        def "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291d6a5b",
      "metadata": {
        "id": "291d6a5b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python310",
      "language": "python",
      "name": "python310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}